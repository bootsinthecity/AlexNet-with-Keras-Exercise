{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AlexNet with Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Import libraries and create an environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Open Terminal\n",
    "2. `conda create -n TF python=3.5 tensorflow pandas numpy jupyter ipython`\n",
    "3. `. activate py35`\n",
    "4. `conda install -c derickl tflearn`\n",
    "5. `cd` to directory of choice\n",
    "6. `jupyter notebook`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "np.random.seed(1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading Oxford 17 category Flower Dataset, Please wait...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0% 60276736 / 60270631\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Succesfully downloaded', '17flowers.tgz', 60270631, 'bytes.')\n",
      "File Extracted\n",
      "Starting to parse images...\n",
      "Parsing Done!\n"
     ]
    }
   ],
   "source": [
    "import tflearn.datasets.oxflower17 as oxflower17\n",
    "x, y = oxflower17.load_data(one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1360, 17)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1360, 224, 224, 3)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Create a sequential model, Compile, and Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Add 5 Convolutional layers:** \n",
    "Batch normalize all convolutional layers\n",
    "\n",
    "**Layer 1:**\n",
    "*Hint: x.shape should help you understand inputs for Convolutional layer*\n",
    "Convolutional layer with 96 filters, 11 by 11 kernel, strides of 4, valid padding, relu activation\n",
    "Max Pooling layer with 2 by 2 pool size, strides of 2, valid padding\n",
    "\n",
    "**Layer 2:**\n",
    "Convolutional layer with 256 filters, 11 by 11 kernel, strides of 1, valid padding, relu activation\n",
    "Max Pooling layer with 2 by 2 pool size, strides of 2, valid padding\n",
    "\n",
    "**Layer 3:**\n",
    "Convolutional layer with 384 filters, 3 by 3 kernel, strides of 1, valid padding, relu activation\n",
    "\n",
    "**Layer 4:**\n",
    "Convolutional layer with 384 filters, 3 by 3 kernel, stride of 1, valid padding, relu activation\n",
    "\n",
    "**Layer 5:**\n",
    "Convolutional layer with 256 filters, 3 by 3 kernel, stride of 1, valid padding, relu activation\n",
    "Max Pooling layer with 2 by 2 pool size, strides of 2, valid padding\n",
    "\n",
    "**Add 3 Fully Connected Layers:**\n",
    "Flatten data to pass to dense layers\n",
    "*Note: Add Dropout of 0.4 and Batch Normalization to each Dense layer\n",
    "\n",
    "**Layer 1:**\n",
    "Dense layer 4096, relu activation \n",
    "*Note: 4096 is an AlexNet parameter*\n",
    "\n",
    "**Layer 2:**\n",
    "Dense Layer 4096, relu activation\n",
    "\n",
    "**Layer 3:**\n",
    "Dense Layer 1000, relu activation\n",
    "\n",
    "**Output Layer**\n",
    "Dense layer with 17 outputs to match the number of classes, softmax activation\n",
    "\n",
    "**Model Summary**\n",
    "Use model.summary to get output shapes and number of parameters\n",
    "\n",
    "**Compile**\n",
    "Compile the model with categorical cross entropy loss, adam optimizer, accuracy metrics\n",
    "\n",
    "**Train the model**\n",
    "Train the model with batch size of 64, 1 epoch to start (you can change this later), and verbose=1\n",
    "Hold back 20% of data for dev set and don't forget to shuffle\n",
    "\n",
    "*Hints:*\n",
    "\n",
    "*Hint 1: model.add(Conv2D(...))*\n",
    "\n",
    "*Hint 2: model.add(BatchNormalization())*\n",
    "\n",
    "*Hint 3: model.add(Dropout())*\n",
    "\n",
    "*Hint 4: model.compile()*\n",
    "\n",
    "*Hint 5: model.fit*\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
