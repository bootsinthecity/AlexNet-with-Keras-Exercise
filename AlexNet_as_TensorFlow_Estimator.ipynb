{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AlexNet with `tf.estimator`\n",
    "\n",
    "Not interested in `Keras`? Kick off the training wheels and write it in raw `TensorFlow`, you rebel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tflearn.datasets.oxflower17 as oxflower17\n",
    "x, y = oxflower17.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make an input function\n",
    "\n",
    "If you're going to use `TensorFlow`, you should get the hang of `tf.data`. It's a little finicky but far easier to use than the old queueing system. And it's incredibly flexible.\n",
    "\n",
    "*Note- the method below for building a dataset from numpy arrays is straightforward, but will run into memory errors for larger datasets. In those cases you'll need to use a more complicated input pipeline.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices((x,y))\n",
    "dataset = dataset.shuffle(500)\n",
    "dataset = dataset.repeat(100)\n",
    "dataset = dataset.batch(128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_fn():\n",
    "    return dataset.make_one_shot_iterator().get_next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_fn()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define a model function\n",
    "\n",
    "Follow the specification here: https://www.tensorflow.org/guide/custom_estimators\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_layers = [(96, 11, 4), \n",
    "               \"maxpool\", \n",
    "             (256, 5, 1),\n",
    "              \"maxpool\",\n",
    "              (384, 3, 1),\n",
    "              (384, 3, 1),\n",
    "              (256, 3, 1),\n",
    "              \"maxpool\"\n",
    "             ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_fn(features, labels, mode, params):\n",
    "    \n",
    "    is_training = mode == tf.estimator.ModeKeys.TRAIN\n",
    "    \n",
    "    print(features.get_shape())\n",
    "    net = tf.identity(features)\n",
    "    \n",
    "    # CONVOLUTIONAL LAYERS\n",
    "    for l in conv_layers:\n",
    "        if l == \"maxpool\":\n",
    "            net = tf.layers.max_pooling2d(net, 3, 2, padding=\"valid\")\n",
    "        else:\n",
    "            f, w, s = l\n",
    "            net = tf.layers.conv2d(net, f, w, strides=(s,s),\n",
    "                                  padding=\"valid\", \n",
    "                                  activation=tf.nn.relu)\n",
    "            net = tf.layers.batch_normalization(net)\n",
    "            \n",
    "    # DENSE LAYERS\n",
    "    net = tf.layers.flatten(net)\n",
    "    for _ in range(2):\n",
    "        net = tf.layers.dense(net, 2048, activation=tf.nn.relu)\n",
    "        net = tf.layers.dropout(net, 0.5, training=is_training)\n",
    "    \n",
    "    # OUTPUT LAYER\n",
    "    logits = tf.layers.dense(net, 17)\n",
    "    probs = tf.nn.softmax(logits)\n",
    "    predicted_classes = tf.argmax(logits, 1)\n",
    "    # PREDICT MODE\n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        predictions = {\n",
    "            \"probabilities\":probs,\n",
    "            \"class_ids\":predicted_classes\n",
    "        }\n",
    "        return tf.estimator.EstimatorSpec(mode, \n",
    "                            predictions=predictions)\n",
    "    # EVALUATE MODE\n",
    "    labels_oh = tf.one_hot(labels, 17)\n",
    "    loss = tf.losses.softmax_cross_entropy(labels_oh, logits)\n",
    "    \n",
    "    accuracy = tf.metrics.accuracy(labels=labels, \n",
    "                                  predictions=predicted_classes)\n",
    "    metrics = {\"accuracy\":accuracy}\n",
    "    tf.summary.scalar(\"accuracy\", accuracy[1])\n",
    "    \n",
    "    if mode == tf.estimator.ModeKeys.EVAL:\n",
    "        return tf.estimator.EstimatorSpec(\n",
    "            mode, loss=loss, eval_metric_ops=metrics\n",
    "        )\n",
    "    # TRAIN MODE\n",
    "    optimizer = tf.train.AdamOptimizer(1e-3)\n",
    "    train_op = optimizer.minimize(loss, \n",
    "                    global_step=tf.train.get_global_step())\n",
    "    \n",
    "    return tf.estimator.EstimatorSpec(mode, loss=loss, \n",
    "                                    train_op=train_op)\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.estimator.Estimator(\n",
    "    model_fn=model_fn, params={}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train(input_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
